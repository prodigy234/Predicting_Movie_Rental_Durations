{"cells":[{"source":"![dvd_image](dvd_image.jpg)\n\nA DVD rental company needs your help! They want to figure out how many days a customer will rent a DVD for based on some features and has approached you for help. They want you to try out some regression models which will help predict the number of days a customer will rent a DVD for. The company wants a model which yeilds a MSE of 3 or less on a test set. The model you make will help the company become more efficient inventory planning.\n\nThe data they provided is in the csv file `rental_info.csv`. It has the following features:\n- `\"rental_date\"`: The date (and time) the customer rents the DVD.\n- `\"return_date\"`: The date (and time) the customer returns the DVD.\n- `\"amount\"`: The amount paid by the customer for renting the DVD.\n- `\"amount_2\"`: The square of `\"amount\"`.\n- `\"rental_rate\"`: The rate at which the DVD is rented for.\n- `\"rental_rate_2\"`: The square of `\"rental_rate\"`.\n- `\"release_year\"`: The year the movie being rented was released.\n- `\"length\"`: Lenght of the movie being rented, in minuites.\n- `\"length_2\"`: The square of `\"length\"`.\n- `\"replacement_cost\"`: The amount it will cost the company to replace the DVD.\n- `\"special_features\"`: Any special features, for example trailers/deleted scenes that the DVD also has.\n- `\"NC-17\"`, `\"PG\"`, `\"PG-13\"`, `\"R\"`: These columns are dummy variables of the rating of the movie. It takes the value 1 if the move is rated as the column name and 0 otherwise. For your convinience, the reference dummy has already been dropped.","metadata":{},"id":"b4ae5707-109f-4cd6-8168-88cac0179d6b","cell_type":"markdown"},{"source":"# Code for Datacamp Project: \"Predicting Movie Rental Durations\"\n\n# Packages and functions\n\n# Import packages\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import ( #linear models\n    LinearRegression, Ridge, Lasso, LogisticRegression\n)\nfrom sklearn.tree import ( # tree-based models\n    DecisionTreeClassifier, DecisionTreeRegressor\n)\nfrom sklearn.ensemble import ( # ensemble models\n    RandomForestClassifier, RandomForestRegressor,\n    GradientBoostingClassifier, GradientBoostingRegressor,\n    AdaBoostClassifier, AdaBoostRegressor\n)\n\n\n# Define explore_df\ndef explore_df(df, method='all'):\n    \"\"\"\n    Function to run describe, head, or info on df.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        The DataFrame to explore.\n    method : {'desc', 'head', 'info', 'all'}\n        Specify the method to use.\n        - 'desc': Display summary statistics using describe().\n        - 'head': Display the first few rows using head().\n        - 'info': Display concise information about the DataFrame using info().\n        - 'na': Display counts of NAs per column and percentage of NAs per column.\n        - 'all': Display all information from above options.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if method.lower() == \"desc\":\n        print(df.describe())\n    elif method.lower() == \"head\":\n        pd.set_option('display.max_columns', None)\n        print(df.head())\n        pd.reset_option('display.max_columns')\n    elif method.lower() == \"info\":\n        print(df.info())\n    elif method.lower() == \"na\":\n        print(f\"\\n\\n<<______NA_COUNT______>>\")\n        print(df.isna().sum())\n        print(f\"\\n\\n<<______NA_PERCENT______>>\")\n        print((df.isna().sum() / df.shape[0])*100)\n    elif method.lower() == \"all\":\n        print(\"<<______HEAD______>>\")\n        pd.set_option('display.max_columns', None)\n        print(df.head())\n        pd.reset_option('display.max_columns')\n        print(f\"\\n\\n<<______DESCRIBE______>>\")\n        print(df.describe())\n        print(f\"\\n\\n<<______INFO______>>\")\n        print(df.info())\n        print(f\"\\n\\n<<______NA_COUNT______>>\")\n        print(df.isna().sum())\n        print(f\"\\n\\n<<______NA_PERCENT______>>\")\n        print((df.isna().sum() / df.shape[0])*100)\n    else:\n        print(\"Methods: 'desc', 'head', 'info' or 'all'\")\n\n\n# Read and explore the data\nrental_info = pd.read_csv('rental_info.csv')\nexplore_df(rental_info)\n\n# Findings/todo based on explore_df:\n# rental_date & return_date not datetime\ndate_columns = ['rental_date', 'return_date']\nrental_info[date_columns] = rental_info[date_columns].apply(pd.to_datetime)\n\n# release year is a float, for memory optimization make int\nrental_info['release_year'] = rental_info['release_year'].astype(int)\n\n# sanity check\nprint(f\"\\n[rental_info dtypes after transformations]:\\n\\n{rental_info.dtypes}\\n\\n\")\n\n\n\n# DataCamp Tasks\n\"\"\"\nTask 1. Create a column named \"rental_length_days\" using the\ncolumns \"return_date\" and \"rental_date\", and add it to the\npandas DataFrame.\n\nThis column should contain information on how many days a DVD\nhas been rented by a customer.\n\"\"\"\n# creating: rental_info['rental_length_day']\nrental_info['rental_length_days'] = (rental_info['return_date'] - rental_info['rental_date']).dt.days\n\n# sanity check\nexplore_df(rental_info['rental_length_days'])\n\n\n\"\"\"\nTask 2. Create two columns of dummy variables from\n\"special_features\", which takes the value of 1 when:\n- The value is \"Deleted Scenes\", storing as a column called \"deleted_scenes\".\n- The value is \"Behind the Scenes\", storing as a column called \"behind_the_scenes\".\n\"\"\"\n# 2.1 - understand the column: special_features\nprint(f\"{rental_info['special_features'].value_counts()}\\n\\n\")\n\n# 2.2 - create deleted_scenes dummy\n# logic: value is 1 if Deleted Scenes is one of the features\n# note: DataCamp is vague clear, it could be they want that\n# Deleted Scenes is the ONLY feature, or that it is PRESENT\nrental_info['deleted_scenes'] = (\n    rental_info['special_features']\n    .apply(lambda x: 'Deleted Scenes' in x) # return true if..\n    .astype(int) # make it 1-0, instead of True-False\n)\n\n# sanity check\nprint(rental_info.loc[[0, 15859],['special_features', 'deleted_scenes']])\n\n\n# 2.3 - create behind_the_scenes dummy\n# logic: value is 1 if Behind the Scenes is one of the features\nrental_info['behind_the_scenes'] = (\n    rental_info['special_features']\n    .apply(lambda x: 'Behind the Scenes' in x)\n    .astype(int)\n)\n\n# sanity check\nprint(rental_info.loc[[0, 15859],['special_features', 'behind_the_scenes']])\n\n\n\"\"\"\nTask 3. Make a pandas DataFrame called X containing all the\nappropriate features you can use to run the regression models,\navoiding columns that leak data about the target.\n\"\"\"\n# create X: exclude rental_date, return_date, rental_length_days, special_features\nX = rental_info.drop(\n    columns=[\n        'rental_date', 'return_date',\n        'rental_length_days', 'special_features'\n    ])\n\n\n\"\"\"\nTask 4. Choose the \"rental_length_days\" as the target column\nand save it as a pandas Series called y.\n\"\"\"\n# create y: rental_length_days\ny = rental_info['rental_length_days']\n\n\n\"\"\"\nTask 5. Split the data into X_train, y_train, X_test, and y_test train and test sets, avoiding any features that leak\ndata about the target variable, and include 20% of the total\ndata in the test set.\n\nSet random_state to 9 whenever you use a function/method\ninvolving randomness, for example, when doing a test-train split.\n\"\"\"\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size = 0.2,\n    random_state = 9\n)\n\n\n\"\"\"\nTask 6. Recommend a model yielding a mean squared error (MSE)\nless than 3 on the test set.\n\nSave the model you would recommend as a variable named\nbest_model, and save its MSE on the test set as best_mse.\n\"\"\"\n# models to test\nsklearn_models_continuousDV = {\n    'LinearRegression': LinearRegression(),\n    'Ridge': Ridge(alpha=1.0),\n    'Lasso': Lasso(alpha=1.0),\n    'DecisionTreeRegressor': DecisionTreeRegressor(),\n    'RandomForestRegressor': RandomForestRegressor(),\n    'GradientBoostingRegressor': GradientBoostingRegressor(),\n    'AdaBoostRegressor': AdaBoostRegressor()\n}\n\n# save model name and corresponding mse value\nresults = {}\n\n# test the models\nfor model_name, model_instance in sklearn_models_continuousDV.items():\n    model_instance.fit(X_train, y_train) # fit\n    y_pred = model_instance.predict(X_test) # predict\n    mse = mean_squared_error(y_test, y_pred) # evaluate (mse)\n    results[model_instance] = mse # save result\n    print(f\"[{model_name}] MSE: {mse:.2f}\\n\") # inform (console)\n    \n# save best_model\nbest_model = min(results, key=lambda x: results[x])\nbest_mse = results[best_model]\nprint(f\"\\n\\nBest Model: {best_model} [MSE = {best_mse:.2f}]\")","metadata":{"executionCancelledAt":null,"executionTime":8349,"lastExecutedAt":1715400058409,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Code for Datacamp Project: \"Predicting Movie Rental Durations\"\n\n# Packages and functions\n\n# Import packages\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import ( #linear models\n    LinearRegression, Ridge, Lasso, LogisticRegression\n)\nfrom sklearn.tree import ( # tree-based models\n    DecisionTreeClassifier, DecisionTreeRegressor\n)\nfrom sklearn.ensemble import ( # ensemble models\n    RandomForestClassifier, RandomForestRegressor,\n    GradientBoostingClassifier, GradientBoostingRegressor,\n    AdaBoostClassifier, AdaBoostRegressor\n)\n\n\n# Define explore_df\ndef explore_df(df, method='all'):\n    \"\"\"\n    Function to run describe, head, or info on df.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        The DataFrame to explore.\n    method : {'desc', 'head', 'info', 'all'}\n        Specify the method to use.\n        - 'desc': Display summary statistics using describe().\n        - 'head': Display the first few rows using head().\n        - 'info': Display concise information about the DataFrame using info().\n        - 'na': Display counts of NAs per column and percentage of NAs per column.\n        - 'all': Display all information from above options.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if method.lower() == \"desc\":\n        print(df.describe())\n    elif method.lower() == \"head\":\n        pd.set_option('display.max_columns', None)\n        print(df.head())\n        pd.reset_option('display.max_columns')\n    elif method.lower() == \"info\":\n        print(df.info())\n    elif method.lower() == \"na\":\n        print(f\"\\n\\n<<______NA_COUNT______>>\")\n        print(df.isna().sum())\n        print(f\"\\n\\n<<______NA_PERCENT______>>\")\n        print((df.isna().sum() / df.shape[0])*100)\n    elif method.lower() == \"all\":\n        print(\"<<______HEAD______>>\")\n        pd.set_option('display.max_columns', None)\n        print(df.head())\n        pd.reset_option('display.max_columns')\n        print(f\"\\n\\n<<______DESCRIBE______>>\")\n        print(df.describe())\n        print(f\"\\n\\n<<______INFO______>>\")\n        print(df.info())\n        print(f\"\\n\\n<<______NA_COUNT______>>\")\n        print(df.isna().sum())\n        print(f\"\\n\\n<<______NA_PERCENT______>>\")\n        print((df.isna().sum() / df.shape[0])*100)\n    else:\n        print(\"Methods: 'desc', 'head', 'info' or 'all'\")\n\n\n# Read and explore the data\nrental_info = pd.read_csv('rental_info.csv')\nexplore_df(rental_info)\n\n# Findings/todo based on explore_df:\n# rental_date & return_date not datetime\ndate_columns = ['rental_date', 'return_date']\nrental_info[date_columns] = rental_info[date_columns].apply(pd.to_datetime)\n\n# release year is a float, for memory optimization make int\nrental_info['release_year'] = rental_info['release_year'].astype(int)\n\n# sanity check\nprint(f\"\\n[rental_info dtypes after transformations]:\\n\\n{rental_info.dtypes}\\n\\n\")\n\n\n\n# DataCamp Tasks\n\"\"\"\nTask 1. Create a column named \"rental_length_days\" using the\ncolumns \"return_date\" and \"rental_date\", and add it to the\npandas DataFrame.\n\nThis column should contain information on how many days a DVD\nhas been rented by a customer.\n\"\"\"\n# creating: rental_info['rental_length_day']\nrental_info['rental_length_days'] = (rental_info['return_date'] - rental_info['rental_date']).dt.days\n\n# sanity check\nexplore_df(rental_info['rental_length_days'])\n\n\n\"\"\"\nTask 2. Create two columns of dummy variables from\n\"special_features\", which takes the value of 1 when:\n- The value is \"Deleted Scenes\", storing as a column called \"deleted_scenes\".\n- The value is \"Behind the Scenes\", storing as a column called \"behind_the_scenes\".\n\"\"\"\n# 2.1 - understand the column: special_features\nprint(f\"{rental_info['special_features'].value_counts()}\\n\\n\")\n\n# 2.2 - create deleted_scenes dummy\n# logic: value is 1 if Deleted Scenes is one of the features\n# note: DataCamp is vague clear, it could be they want that\n# Deleted Scenes is the ONLY feature, or that it is PRESENT\nrental_info['deleted_scenes'] = (\n    rental_info['special_features']\n    .apply(lambda x: 'Deleted Scenes' in x) # return true if..\n    .astype(int) # make it 1-0, instead of True-False\n)\n\n# sanity check\nprint(rental_info.loc[[0, 15859],['special_features', 'deleted_scenes']])\n\n\n# 2.3 - create behind_the_scenes dummy\n# logic: value is 1 if Behind the Scenes is one of the features\nrental_info['behind_the_scenes'] = (\n    rental_info['special_features']\n    .apply(lambda x: 'Behind the Scenes' in x)\n    .astype(int)\n)\n\n# sanity check\nprint(rental_info.loc[[0, 15859],['special_features', 'behind_the_scenes']])\n\n\n\"\"\"\nTask 3. Make a pandas DataFrame called X containing all the\nappropriate features you can use to run the regression models,\navoiding columns that leak data about the target.\n\"\"\"\n# create X: exclude rental_date, return_date, rental_length_days, special_features\nX = rental_info.drop(\n    columns=[\n        'rental_date', 'return_date',\n        'rental_length_days', 'special_features'\n    ])\n\n\n\"\"\"\nTask 4. Choose the \"rental_length_days\" as the target column\nand save it as a pandas Series called y.\n\"\"\"\n# create y: rental_length_days\ny = rental_info['rental_length_days']\n\n\n\"\"\"\nTask 5. Split the data into X_train, y_train, X_test, and y_test train and test sets, avoiding any features that leak\ndata about the target variable, and include 20% of the total\ndata in the test set.\n\nSet random_state to 9 whenever you use a function/method\ninvolving randomness, for example, when doing a test-train split.\n\"\"\"\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size = 0.2,\n    random_state = 9\n)\n\n\n\"\"\"\nTask 6. Recommend a model yielding a mean squared error (MSE)\nless than 3 on the test set.\n\nSave the model you would recommend as a variable named\nbest_model, and save its MSE on the test set as best_mse.\n\"\"\"\n# models to test\nsklearn_models_continuousDV = {\n    'LinearRegression': LinearRegression(),\n    'Ridge': Ridge(alpha=1.0),\n    'Lasso': Lasso(alpha=1.0),\n    'DecisionTreeRegressor': DecisionTreeRegressor(),\n    'RandomForestRegressor': RandomForestRegressor(),\n    'GradientBoostingRegressor': GradientBoostingRegressor(),\n    'AdaBoostRegressor': AdaBoostRegressor()\n}\n\n# save model name and corresponding mse value\nresults = {}\n\n# test the models\nfor model_name, model_instance in sklearn_models_continuousDV.items():\n    model_instance.fit(X_train, y_train) # fit\n    y_pred = model_instance.predict(X_test) # predict\n    mse = mean_squared_error(y_test, y_pred) # evaluate (mse)\n    results[model_instance] = mse # save result\n    print(f\"[{model_name}] MSE: {mse:.2f}\\n\") # inform (console)\n    \n# save best_model\nbest_model = min(results, key=lambda x: results[x])\nbest_mse = results[best_model]\nprint(f\"\\n\\nBest Model: {best_model} [MSE = {best_mse:.2f}]\")","lastExecutedByKernel":"003fcf0e-bbfd-4586-9e9c-a6146d113155","outputsMetadata":{"0":{"height":610,"type":"stream"}}},"id":"a7ede566-910a-445c-b11a-68d192ac8506","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"<<______HEAD______>>\n                 rental_date                return_date  amount  release_year  \\\n0  2005-05-25 02:54:33+00:00  2005-05-28 23:40:33+00:00    2.99        2005.0   \n1  2005-06-15 23:19:16+00:00  2005-06-18 19:24:16+00:00    2.99        2005.0   \n2  2005-07-10 04:27:45+00:00  2005-07-17 10:11:45+00:00    2.99        2005.0   \n3  2005-07-31 12:06:41+00:00  2005-08-02 14:30:41+00:00    2.99        2005.0   \n4  2005-08-19 12:30:04+00:00  2005-08-23 13:35:04+00:00    2.99        2005.0   \n\n   rental_rate  length  replacement_cost                special_features  \\\n0         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}   \n1         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}   \n2         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}   \n3         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}   \n4         2.99   126.0             16.99  {Trailers,\"Behind the Scenes\"}   \n\n   NC-17  PG  PG-13  R  amount_2  length_2  rental_rate_2  \n0      0   0      0  1    8.9401   15876.0         8.9401  \n1      0   0      0  1    8.9401   15876.0         8.9401  \n2      0   0      0  1    8.9401   15876.0         8.9401  \n3      0   0      0  1    8.9401   15876.0         8.9401  \n4      0   0      0  1    8.9401   15876.0         8.9401  \n\n\n<<______DESCRIBE______>>\n             amount  release_year  ...      length_2  rental_rate_2\ncount  15861.000000  15861.000000  ...  15861.000000   15861.000000\nmean       4.217161   2006.885379  ...  14832.841876      11.389287\nstd        2.360383      2.025027  ...   9393.431996      10.005293\nmin        0.990000   2004.000000  ...   2116.000000       0.980100\n25%        2.990000   2005.000000  ...   6561.000000       0.980100\n50%        3.990000   2007.000000  ...  12996.000000       8.940100\n75%        4.990000   2009.000000  ...  21904.000000      24.900100\nmax       11.990000   2010.000000  ...  34225.000000      24.900100\n\n[8 rows x 12 columns]\n\n\n<<______INFO______>>\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 15861 entries, 0 to 15860\nData columns (total 15 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   rental_date       15861 non-null  object \n 1   return_date       15861 non-null  object \n 2   amount            15861 non-null  float64\n 3   release_year      15861 non-null  float64\n 4   rental_rate       15861 non-null  float64\n 5   length            15861 non-null  float64\n 6   replacement_cost  15861 non-null  float64\n 7   special_features  15861 non-null  object \n 8   NC-17             15861 non-null  int64  \n 9   PG                15861 non-null  int64  \n 10  PG-13             15861 non-null  int64  \n 11  R                 15861 non-null  int64  \n 12  amount_2          15861 non-null  float64\n 13  length_2          15861 non-null  float64\n 14  rental_rate_2     15861 non-null  float64\ndtypes: float64(8), int64(4), object(3)\nmemory usage: 1.8+ MB\nNone\n\n\n<<______NA_COUNT______>>\nrental_date         0\nreturn_date         0\namount              0\nrelease_year        0\nrental_rate         0\nlength              0\nreplacement_cost    0\nspecial_features    0\nNC-17               0\nPG                  0\nPG-13               0\nR                   0\namount_2            0\nlength_2            0\nrental_rate_2       0\ndtype: int64\n\n\n<<______NA_PERCENT______>>\nrental_date         0.0\nreturn_date         0.0\namount              0.0\nrelease_year        0.0\nrental_rate         0.0\nlength              0.0\nreplacement_cost    0.0\nspecial_features    0.0\nNC-17               0.0\nPG                  0.0\nPG-13               0.0\nR                   0.0\namount_2            0.0\nlength_2            0.0\nrental_rate_2       0.0\ndtype: float64\n\n[rental_info dtypes after transformations]:\n\nrental_date         datetime64[ns, UTC]\nreturn_date         datetime64[ns, UTC]\namount                          float64\nrelease_year                      int64\nrental_rate                     float64\nlength                          float64\nreplacement_cost                float64\nspecial_features                 object\nNC-17                             int64\nPG                                int64\nPG-13                             int64\nR                                 int64\namount_2                        float64\nlength_2                        float64\nrental_rate_2                   float64\ndtype: object\n\n\n<<______HEAD______>>\n0    3\n1    2\n2    7\n3    2\n4    4\nName: rental_length_days, dtype: int64\n\n\n<<______DESCRIBE______>>\ncount    15861.000000\nmean         4.525944\nstd          2.635108\nmin          0.000000\n25%          2.000000\n50%          5.000000\n75%          7.000000\nmax          9.000000\nName: rental_length_days, dtype: float64\n\n\n<<______INFO______>>\n<class 'pandas.core.series.Series'>\nRangeIndex: 15861 entries, 0 to 15860\nSeries name: rental_length_days\nNon-Null Count  Dtype\n--------------  -----\n15861 non-null  int64\ndtypes: int64(1)\nmemory usage: 124.0 KB\nNone\n\n\n<<______NA_COUNT______>>\n0\n\n\n<<______NA_PERCENT______>>\n0.0\n{Trailers,Commentaries,\"Behind the Scenes\"}                     1308\n{Trailers}                                                      1139\n{Trailers,Commentaries}                                         1129\n{Trailers,\"Behind the Scenes\"}                                  1122\n{\"Behind the Scenes\"}                                           1108\n{Commentaries,\"Deleted Scenes\",\"Behind the Scenes\"}             1101\n{Commentaries}                                                  1089\n{Commentaries,\"Behind the Scenes\"}                              1078\n{Trailers,\"Deleted Scenes\"}                                     1047\n{\"Deleted Scenes\",\"Behind the Scenes\"}                          1035\n{\"Deleted Scenes\"}                                              1023\n{Commentaries,\"Deleted Scenes\"}                                 1011\n{Trailers,Commentaries,\"Deleted Scenes\",\"Behind the Scenes\"}     983\n{Trailers,Commentaries,\"Deleted Scenes\"}                         916\n{Trailers,\"Deleted Scenes\",\"Behind the Scenes\"}                  772\nName: special_features, dtype: int64\n\n\n                                      special_features  deleted_scenes\n0                       {Trailers,\"Behind the Scenes\"}               0\n15859  {Trailers,\"Deleted Scenes\",\"Behind the Scenes\"}               1\n                                      special_features  behind_the_scenes\n0                       {Trailers,\"Behind the Scenes\"}                  1\n15859  {Trailers,\"Deleted Scenes\",\"Behind the Scenes\"}                  1\n[LinearRegression] MSE: 2.94\n\n[Ridge] MSE: 2.94\n\n[Lasso] MSE: 3.81\n\n[DecisionTreeRegressor] MSE: 2.17\n\n[RandomForestRegressor] MSE: 2.03\n\n[GradientBoostingRegressor] MSE: 2.43\n\n[AdaBoostRegressor] MSE: 3.16\n\n\n\nBest Model: RandomForestRegressor() [MSE = 2.03]\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}